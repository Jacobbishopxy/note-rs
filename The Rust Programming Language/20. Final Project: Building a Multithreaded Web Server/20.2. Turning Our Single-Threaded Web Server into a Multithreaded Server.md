# 将单线程 Web 服务变为多线程

现在的服务一次处理一个请求，意味着它再完成第一个连接的处理之前不会处理第二个连接。如果服务接收的请求越来越多，这类串行操作会使性能越来越差。如果一个请求花费很长时间来处理，之后的请求则不得不等待这个长请求结束，即便这些新请求可以被很快的处理完。我们需要修复这个情况，不过首先让我们尝试一下这个问题。

## 当前的服务实现中模拟慢请求

让我们看一下一个慢请求是如何影响当前服务实现中的其它请求：

```rust
use std::thread;
use std::time::Duration;
// --snip--

fn handle_connection(mut stream: TcpStream) {
    // --snip--

    let get = b"GET / HTTP/1.1\r\n";
    let sleep = b"GET /sleep HTTP/1.1\r\n";

    let (status_line, filename) = if buffer.starts_with(get) {
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else if buffer.starts_with(sleep) {
        thread::sleep(Duration::from_secs(5));
        ("HTTP/1.1 200 OK\r\n\r\n", "hello.html")
    } else {
        ("HTTP/1.1 404 NOT FOUND\r\n\r\n", "404.html")
    };

    // --snip--
}
```

这里创建了第二个请求`sleep`，当接收到/sleep 请求时，渲染 HTML 页面之前将先休眠 5 秒。

现在就可以看到我们的服务有多么的原始：真实的库将会以更简洁的方式处理多请求识别问题！

...

## 使用线程池改进吞吐量

*线程池*thread pool 是一组预先分配的等待或准备处理任务的线程。当程序收到一个新任务，线程池中的一个线程会被分配任务，这个线程会离开并处理任务。在第一个线程处理任务的同时，其余的线程则可用于处理其它接收到的任务。当第一个线程处理完任务时，它会回到线程池中等待处理新任务。线程池允许你并发的处理连接，增加服务的吞吐量。

我们限制池中的线程在一个小数量里，来保护我们被 Denial of Service（DoS）攻击；如果程序为每一个接收的请求都新建一个线程，有人向服务发起千万级的请求时会耗尽服务器的资源并导致所有请求的处理都被终止。

不同于分配无限的线程，线程池中将有固定数量的等待线程。当新请求进来，将请求发送到线程池中做处理。线程池会维护一个接收请求的队列。每一个线程会从队列中取出一个请求，处理请求，接着向队列索要另一个请求。通过这个设计，我们可以并发处理`N`个请求，这里的`N`是线程数。如果每一个线程都用于响应慢请求，随后的请求还是会阻塞队列，但是我们相较于之前，增加了慢请求的处理数量。

这个技术只是多种改善 web 服务吞吐量的方法之一。其它方法你可能探索的有 fork/join 以及单线程的异步 I/O 模型。...

在开始实现线程池之前，让我们讨论一下线程池应用看起来应该是什么样子的。当你尝试设计代码，首先编写客户端接口可以帮助指导设计。编写 API 可以构建你想调用的方法；在结构内实现功能而不是实现功能后再设计公有 API。

....

### 为每一个请求分配线程的代码结构

首先让我们看一下如果为每一个连接创建一个新线程是什么样子。

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();

    for stream in listener.incoming() {
        let stream = stream.unwrap();

        thread::spawn(|| {
            handle_connection(stream);
        });
    }
}
```

...

### 为有限数量的线程创建一个类似的接口

以下代码展示了假设的`ThreadPool`结构接口，而不是`thread::spawn`：

```rust
fn main() {
    let listener = TcpListener::bind("127.0.0.1:7878").unwrap();
    let pool = ThreadPool::new(4);

    for stream in listener.incoming() {
        let stream = stream.unwrap();

        pool.execute(|| {
            handle_connection(stream);
        });
    }
}
```

我们用`ThreadPool::new`来创建一个新的线程池，它有配置线程数量的参数。接着在`for`循环中，`pool.execute`拥有与`thread::spawn`类似的接口，其中接受一个闭包并返回一个池中的线程用于运行。代码暂不可编译。

### 使用编译器驱动开发构建一个`ThreadPool`结构体

创建*src/lib.rs*文件，定义`ThreadPool`以及关联函数：

```rust
pub struct ThreadPool;

impl ThreadPool {
    pub fn new(size: usize) -> ThreadPool {
        ThreadPool
    }
}
```

编译：

```null
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0599]: no method named `execute` found for struct `ThreadPool` in the current scope
  --> src/bin/main.rs:16:14
   |
16 |         pool.execute(|| {
   |              ^^^^^^^ method not found in `ThreadPool`

error: aborting due to previous error

For more information about this error, try `rustc --explain E0599`.
error: could not compile `hello`

To learn more, run the command again with --verbose.
```

我们需要实现`execute`函数来获取传递的闭包并将其传递给池中的空闲线程执行。

我们会在`ThreadPool`上定义`execute`方法，其入参为一个闭包。闭包作为参数可以使用三个不同的特性：`Fn`、`FnMut`和`FnOnce`。我们需要决定这里使用哪一种闭包。我们需要的实现与标准库的`thread::spawn`类似，所以我们查看`thread::spawn`函数的签名在其参数中使用了哪种限定。文档：

```rust
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T + Send + 'static,
        T: Send + 'static
```

`F`类型参数是这里我们关心的一个点；`T`类型参数与返回值相关，我们不需要关心它。我们可以看到`spawn`使用`FnOnce`作为`F`的特性限定。这可能也是我们需要的，因为我们最终将传递给`execute`的参数传给`spawn`。我们可以更加确信`FnOnce`是我们希望使用的特性，因为运行一个请求的线程将只需要执行请求的闭包一次，即符合`FnOnce`的`Once`。

`F`类型参数另外还有`Send`的特性限定以及生命周期限定`'static`，这对我们的情况有用：我们需要`Send`把闭包从一个线程传输至另一个线程，同时`'static`是因为我们不知道线程会执行多长时间。让我们在`ThreadPool`上创建一个`execute`方法，其接受一个带有以下限定的泛型参数类型`F`：

```rust
impl ThreadPool {
    // --snip--
    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
    }
}
```

我们还是在`FnOnce`之后使用`()`，因为`FnOnce`代表一个接受无参数并返回单元类型`()`的闭包。

这里再次增加了`execute`方法的最小化实现：它没有做任何工作，只是尝试让代码能够编译。

...

### 在`new`中验证线程数量

我们还没有对`new`和`execute`的参数做任何事情。让我们实现这些函数体。首先考虑`new`。之前我们选择无符号的`size`类型作为参数，因为负数的线程没有任何意义。然而 0 个线程同样没有意义，而 0 是有效的`usize`。我们将添加一个大于 0 的检查器在返回`ThreadPool`实例之前，用`assert!`宏在得到 0 时 panic：

```rust
impl ThreadPool {
    /// Create a new ThreadPool.
    ///
    /// The size is the number of threads in the pool.
    ///
    /// # Panics
    ///
    /// The `new` function will panic if the size is zero.
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        ThreadPool
    }

    // --snip--
}
```

...

相比使用`assert!`宏，我们可以让`new`返回一个`Result`。但是这里我们选择一个没有任何线程的线程池应该是不可恢复的错误。如果你想做的更好，尝试编写以下签名的`new`：

```rust
pub fn new(size: usize) -> Result<ThreadPool, PoolCreationError> {
```

### 分配空间用于存储线程

现在我们知道拥有有效数量的线程存储于池中，我们可以创建线程并在返回之前把它们存储进`ThreadPool`结构体。但是我们该如何“存储”一个线程？再观察一下`thread::spawn`签名：

```rust
pub fn spawn<F, T>(f: F) -> JoinHandle<T>
    where
        F: FnOnce() -> T + Send + 'static,
        T: Send + 'static
```

`spawn`函数返回一个`JoinHandle<T>`，这里`T`是闭包返回的类型。让我们也尝试使用`JoinHandle`并观察会发生什么。在我们这个案例，传递给线程池的闭包将处理连结并没有返回，所以`T`将是单元类型`()`。

以下代码可以编译但是暂时还不能创建任何线程。我们修改`ThreadPool`的定义使其用于存储一个向量的`thread::JoinHandle<()>`实例，使用`size`容量来初始化，设定一个`for`循环用于运行创建线程的代码，并返回包含这些线程的`ThreadPool`实例：

```rust
use std::thread;

pub struct ThreadPool {
    threads: Vec<thread::JoinHandle<()>>,
}

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let mut threads = Vec::with_capacity(size);

        for _ in 0..size {
            // create some threads and store them in the vector
        }

        ThreadPool { threads }
    }

    // --snip--
}
```

我们把`std::thread`引入作用域，因为我们使用`thread::JoinHandle`作为`ThreadPool`中的向量元素类型。

一旦得到了有效的数量后，`ThreadPool`新建一个存放`size`个元素的向量。我们还未在本书中使用过`with_capacity`函数，它与`Vec::new`的工作一样，但是有一个重要的区别：前者为向量预先分配空间。因为已经知道了向量中所需`size`个元素，预先分配比`Vec::new`要稍微有效率一些，因为`Vec::new`随着插入元素而重新改变大小。

当你再次执行`cargo check`，你将看到一些警告，不过编译可以成功。

### `Worker`结构体负责从`ThreadPool`中将代码传递给线程

我们在之前的`for`循环中留下了创建线程的注释。这里看看实际该如何创建线程。标准库提供的`thread::spawn`是一种创建线程的方式，它期望获取一些能在线程创建后立马执行的代码。然而在我们的例子中，我们希望创建的线程是可以等待以便之后传递的代码。标准库的线程实现并没有包含这样的方法；我们需要手动实现。

我们引入一个介于`ThreadPool`和线程的新的数据结构来实现这个行为。我们称这个数据结构为`Worker`，这是一个池实现的一个常见概念。想象一下在餐厅厨房工作的员工；员工等待来自客户的订单，他们负责接收订单并完成它们。

不同于存储一个向量的`JoinHandle<()>`实例在线程池，我们存储`Worker`结构体的实例。每一个`Worker`将存储一个单独的`JoinHandle<()>`实例。接着我们实现`Worker`用于接受一个闭包的方法，该方法发送闭包给已经运行的线程来执行。我们将给每个 worker 一个`id`，在日志或调试时我们可以区分它们。

让我们按以下步骤进行修改：

1. 定义一个`Worker`结构体，存储`id`和`JoinHandle<()>`。
1. 修改`ThreadPool`，存储`Worker`实例的向量。
1. 定义`Worker::new`函数，接受`id`并返回`Worker`实例，该实例存储`id`以及一个接受空闭包的线程。
1. 在`ThreadPool::new`中，使用`for`循环计数生成`id`，使用这个`id`创建新`Worker`，并存储该 worker 至向量中。

```rust
use std::thread;

pub struct ThreadPool {
    workers: Vec<Worker>,
}

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id));
        }

        ThreadPool { workers }
    }
    // --snip--
}

struct Worker {
    id: usize,
    thread: thread::JoinHandle<()>,
}

impl Worker {
    fn new(id: usize) -> Worker {
        let thread = thread::spawn(|| {});

        Worker { id, thread }
    }
}
```

我们把`ThreadPool`的字段从`threads`变为了`workers`，因为它现在存储的是`Worker`实例而不是`JoinHandle<()>`实例。我们用`for`循环的计数作为`Worker::new`的参数，并存储每个`Worker`于`workers`字段中。

外部代码（像是在*src/bin/main.rs*里的服务）不需要知道在`ThreadPool`内使用`Worker`结构体的实现细节，所以我们使`Worker`结构体与其`new`函数私有。`Worker::new`函数的接受`id`后再存储由空闭包生成的`JoinHandle<()>`实例。

上述代码可以编译，也将存储由`ThreadPool::new`指定数量的`Worker`实例。但是我们*仍然*没有处理`execute`中得到的闭包。

### 使用通道向线程发送请求

我们期望在`execute`方法中获得执行用的闭包。但是在创建`ThreadPool`的过程中，每一个`Worker`需要向`thread::spawn`传递一个闭包。

我们希望刚创建的`Worker`结构体能够从`ThreadPool`的队列中获取需要执行的代码，并发送到线程中执行它们。

在第十六章中，我们学习过的*通道*--一个在两个线程中沟通的方法--对于我们的例子来说是完美的。我们用通道作为任务队列，`execute`将通过`ThreadPool`发送任务给`Worker`实例。以下为计划：

1. `ThreadPool`创建一个通道，作为一个通道的发送端
1. 每个`Worker`作为通道的接收端
1. 创建一个新的`Job`结构体，存放向通道中发送的闭包
1. `execute`方法将发送期望执行的任务
1. 在线程中，`Worker`将遍历通道的接收端并执行任何接收到的任务

让我们开始在`ThreadPool::new`中创建一个通道，并让`ThreadPool`实例作为发送端。`Job`结构体暂时没有任何内容，但是将作为在通道中发送的类型。

```rust
// --snip--
use std::sync::mpsc;

pub struct ThreadPool {
    workers: Vec<Worker>,
    sender: mpsc::Sender<Job>,
}

struct Job;

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id));
        }

        ThreadPool { workers, sender }
    }
    // --snip--
}
```

在`ThreadPool::new`中，我们创建新通道并使用线程池维持发送端。这将通过编译，仍留有警告。

让我们尝试在线程池创建 worker 时，将通道的接收端传递给他们。我们要知道在 worker 所分配的线程中使用通道的接收端，所以我们将在闭包中引用`receiver`参数。以下代码还不能编译：

```rust
impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, receiver));
        }

        ThreadPool { workers, sender }
    }
    // --snip--
}

// --snip--

impl Worker {
    fn new(id: usize, receiver: mpsc::Receiver<Job>) -> Worker {
        let thread = thread::spawn(|| {
            receiver;
        });

        Worker { id, thread }
    }
}
```

我们做了一些小改动：我们传递通道的接收端给`Worker::new`，接着我们在闭包中使用它。

当检测代码是，得到以下错误：

```null
$ cargo check
    Checking hello v0.1.0 (file:///projects/hello)
error[E0382]: use of moved value: `receiver`
  --> src/lib.rs:27:42
   |
22 |         let (sender, receiver) = mpsc::channel();
   |                      -------- move occurs because `receiver` has type `std::sync::mpsc::Receiver<Job>`, which does not implement the `Copy` trait
...
27 |             workers.push(Worker::new(id, receiver));
   |                                          ^^^^^^^^ value moved here, in previous iteration of loop

error: aborting due to previous error

For more information about this error, try `rustc --explain E0382`.
error: could not compile `hello`

To learn more, run the command again with --verbose.
```

代码尝试传递`receiver`给若干个`Worker`实例。这不可以，回想第十六章：通道的实现是 Rust 提供若干*生产者*，一个*消费者*。这意味着我们不能通过克隆通道的消费端来解决这个问题。即使我们可以那么做，这也不是我们想用的技巧；我们希望通过共享单个`receiver`来分配任务给所有的线程。

另外，从通道队列中提取一个任务出来涉及到修改`receiver`，所以线程需要一个安全的方法用于共享和修改`receiver`；否则的话，我们可能面临数据竞争的状况。

回想第十六章中讨论的线程安全的智能指针：在若干线程中共享所有权，并允许线程修改该值，我们需要用到`Arc<Mutex<T>>`。`Arc`类型让若干 worker 拥有同一个接收者，同时`Mutex`确保同一时间只有一个 worker 从 receiver 获取任务。

```rust
use std::sync::Arc;
use std::sync::Mutex;
// --snip--

impl ThreadPool {
    // --snip--
    pub fn new(size: usize) -> ThreadPool {
        assert!(size > 0);

        let (sender, receiver) = mpsc::channel();

        let receiver = Arc::new(Mutex::new(receiver));

        let mut workers = Vec::with_capacity(size);

        for id in 0..size {
            workers.push(Worker::new(id, Arc::clone(&receiver)));
        }

        ThreadPool { workers, sender }
    }

    // --snip--
}

// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        // --snip--
    }
}
```

在`ThreadPool::new`中，我们把通道的接收端放入一个`Arc`和一个`Mutex`中。对于每一个新 worker，克隆`Arc`来增加引用计数，这样这些 worker 就可以共享接收端的所有权了。

通过这些改动，代码可以编译了！

### 实现`execute`方法

让我们最后在`ThreadPool`上来实现`execute`方法。我们同时修改`Job`结构体成为一个特性对象的类型别名，其代表`execute`接收的闭包类型。

```rust
// --snip--

type Job = Box<dyn FnOnce() + Send + 'static>;

impl ThreadPool {
    // --snip--

    pub fn execute<F>(&self, f: F)
    where
        F: FnOnce() + Send + 'static,
    {
        let job = Box::new(f);

        self.sender.send(job).unwrap();
    }
}

// --snip--
```

使用`execute`得到的闭包新建`Job`实例之后，我们将这些任务从通道的发送端发出。我们调用`send`上的`unwarp`，因为发送可能会失败。例如我们停止了所有的线程，意味着接收端停止接受新消息。现在我们不能停止线程的执行：只要线程池存在，我们的线程便持续执行。使用`unwarp`是因为我们知道失败不可能发生，尽管编译器不知道。

但是我们还没有完！在 worker 中，传递给`thread::spawn`的闭包仅引用了通道的接收端。我们需要闭包一直循环，向通道的接收端请求任务，并在得到任务时执行它们：

```rust
// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || loop {
            let job = receiver.lock().unwrap().recv().unwrap();

            println!("Worker {} got a job; executing.", id);

            job();
        });

        Worker { id, thread }
    }
}
```

这里我们先调用`receiver`的`lock`来获取互斥器，接着调用`unwrap`来让任何错误发生时 panic。如果互斥器处于一种叫做*被污染*poisoned 的状态时，获取锁可能会失败，这可能发生在其它线程在持有锁时 panic 了并且没有释放锁。在这种情况下，调用`unwrap`使线程 panic 是正确的行为。...

如果锁定了互斥器，我们调用`recv`从通道中获取一个`Job`。最后的`unwrap`也绕过了一些错误，这可能发生在持有通道发送端的线程停止时，类似于如果接收端关闭时`send`方法是如何返回`Err`的。

调用`recv`阻塞当前线程，如果还没有任务，当前线程会等待直到有可用的任务。`Mutex<T>`确保同一时间只有一个`Worker`线程尝试请求任务。

通过这个实现，我们的线程池可以运行了！执行`cargo run`并发起一些请求：

```null
$ cargo run
   Compiling hello v0.1.0 (file:///projects/hello)
warning: field is never read: `workers`
 --> src/lib.rs:7:5
  |
7 |     workers: Vec<Worker>,
  |     ^^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(dead_code)]` on by default

warning: field is never read: `id`
  --> src/lib.rs:48:5
   |
48 |     id: usize,
   |     ^^^^^^^^^

warning: field is never read: `thread`
  --> src/lib.rs:49:5
   |
49 |     thread: thread::JoinHandle<()>,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: 3 warnings emitted

    Finished dev [unoptimized + debuginfo] target(s) in 1.40s
     Running `target/debug/main`
Worker 0 got a job; executing.
Worker 2 got a job; executing.
Worker 1 got a job; executing.
Worker 3 got a job; executing.
Worker 0 got a job; executing.
Worker 2 got a job; executing.
Worker 1 got a job; executing.
Worker 3 got a job; executing.
Worker 0 got a job; executing.
Worker 2 got a job; executing.
```

成功！现在我们有了一个可以一步执行廉洁的线程池！它绝对不会创建超过四个线程，所以当服务收到大量请求时系统也不会负担过重。如果请求/sleep，服务也能够通过另外一个线程处理其它请求。

...

在学习了第十八章的`while let`循环后，你看会思考为什么我们不用它编写 worker 线程，如下：

```rust
// --snip--

impl Worker {
    fn new(id: usize, receiver: Arc<Mutex<mpsc::Receiver<Job>>>) -> Worker {
        let thread = thread::spawn(move || {
            while let Ok(job) = receiver.lock().unwrap().recv() {
                println!("Worker {} got a job; executing.", id);

                job();
            }
        });

        Worker { id, thread }
    }
}
```

上述代码可以编译和运行，但是不会有所期望线程行为：一个慢请求仍然会导致其它请求等待执行。其中原因比较微妙：`Mutex`结构体没有共有`unlock`方法，因为锁的所有权依赖`lock`方法返回的`LockResult<MutexGuard<T>>`里的`MutexGuard<T>`的生命周期。在编译时，借用检查器可以强制一个规则，即不会在没有持有锁的情况下访问`Mutex`守护的资源。如果没有思考`MutexGuard<T>`的生命周期，上述实现可能导致比预期更久的持有锁。

之前的例子中使用`let job = receiver.lock().unwrap().recv().unwrap();`有效是因为`let`，当`let`表达式结束时，任何用在表达式的临时值会被立刻丢弃。然而，`while let`（以及`if let`和`match`）不会丢弃临时值知道相关作用域结束。上述代码中，锁一直持续到了调用`job()`，意味着其它 worker 不可以接收任务。
