# 原子操作

Rust 原子操作的内存模型公然的抄袭了 C++20。这并不是因为这个模型非常的优秀或事易于理解。实际上这个模型非常的复杂，并且还有若干的缺陷。尽管如此，这是一个务实的让步。至少我们可以受益于现有的工具，并研究借鉴 C/C++ 的内存模型。（你将经常看到这个模型牵扯到 C/C++11，或者就是 C11。C 仅仅拷贝了 C++ 的内存模型；而 C++11 是该模型的第一个版本，后续进行了一些 bug 修复）。

在这本书内要完全的解释这个模型是不可能的。因为它是根据疯狂的因果关系图而构建的，需要一整本书才能合理的解释它。如果你需要所有的细节，请查阅[C++规范](https://en.cppreference.com/w/cpp/atomic/memory_order)。这里我们将尝试覆盖基础以及 Rust 开发者会面临的一些问题。

C++ 的内存模型是一个基本的桥梁用于连接这些鸿沟：我们对语义的要求，编译器的优化要求，以及硬件对各种混乱状态的要求。我们需要编写的程序完全的执行我们的命令。这不是很伟大吗？

## 编译器重排

编译器本质上希望能够做各种复杂的转换来减少数据依赖和消除 dead code。特别是它们可能从根本上改变实际事件的顺序，或者让事件永不发生！如果我们编写以下代码：

```txt
x = 1;
y = 3;
x = 2;
```

那么编译器可能会把这个代码转换成：

```txt
x = 2;
y = 3;
```

这就完全倒置了原有事件的顺序，并且完全消除了一个事件。从单线程的角度来看，这是完全察觉不到的：所有的声明都在同一个状态下执行。但是如果我们的程序是多线程的，我们可能确实需要在 `y` 被赋值前将 `x` 赋值为 1。我们希望编译器能够优化这类代码，因为它们可能提升很多性能。另一方面，我们也同样需要依赖程序能够完全按照我们的指令执行。

## 硬件重排

另一方面，即使编译器完全理解我门的需求并且回应我们的意愿，我们的硬件还是可能会让我们陷入麻烦。这个麻烦来源于内存分层模式下的 CPUs。在你的硬件上，有一个全局的共享内存区域，但是对于每个 CPU 核心来说，这个区域实在是太远了，并且访问起来会很慢。每个 CPU 宁愿在其本地的缓存上操作数据，只有在缓存中没有数据的时候才会和共享内存打交道。

毕竟这才是缓存的全部意义对吧？如果每一次读取缓存都要再去检查共享内存，看看数据有没有变化，那么缓存的意义何在？最终的结果就是，硬件不能保证相同的事件在两个不同的线程里一定有相同的执行顺序。如果要保证这点，我们必须有一些特殊的方法告诉 CPU 稍微变笨一点。

例如，告诉编译器输出这样的逻辑：

```txt
initial state: x = 0, y = 1

THREAD 1        THREAD2
y = 3;          if x == 1 {
x = 1;              y *= 2;
                }
```

理想情况下这个程序会有两种可能的最终状态：

- `y = 3`：（线程 2 在线程 1 完成前进行检查）

- `y = 6`：（线程 2 在线程 1 万次后进行检查）

然而还有第三种可能的状态是硬件允许的：

- `y = 2`：（线程 2 看到 `x = 1`，并且没有看到 `y = 3`，然后覆盖了 `y = 3`）

值得注意的是不同的 CPU 提供不同的保障。通常可以把硬件分为两类：强顺序的和弱顺序的。大多数 x86/64 提供强顺序的保障，而 ARM 提供弱顺序的保障。对于并发编程，这便有两种结果：

- 在强有序的硬件上要求强顺序保证的开销小甚至与无，因为其已经提供了强有序的保障。弱保证可能只在弱顺序硬件上获得性能优势。

- 在强顺序的硬件上要求太弱的顺序保证有可能也会碰巧成功，即使你的程序是错误的。如果可能的话，在弱保证硬件上测试并发算法。

## 数据访问

C++ 内存模型缩小了我们与程序之前因果关系的差距。通常而言，就是要确定程序的各个部分以及运行它们的多个线程之前的时间先后关系。这样使得在没有严格的 happens-before 关系被建立的前提下，硬件和编译器有空间来更为激进的优化程序，而在关系被建立的情况下会迫使优化变得很小心。我们与这些关系交流的方法是通过*数据访问*以及*原子访问*来进行的。

数据访问时程序设计世界的根基。它们都是非同步的，并且编译器可以任意的激进的优化它们。尤其是，编译器认定数据访问都是单线程的，所以可以对它随意地重排。硬件也可以把数据访问的重排的结果移植到其他的线程上去，无论结果多么的滞后和不一致都可以。数据访问最重要的问题是数据竞争。数据访问对于硬件和编译器都非常的友好，但是我们所看到的，它们提供的语义对于同步程序而言很糟糕。实际上是太弱了。

**实际上仅仅使用数据访问来编写同步代码是不可能的。**

原子访问才是我们告诉硬件和编译器我们的程序是多线程的。每个原子访问可以被标记一个顺序用于指定其与其他的访问为何种关系。在实践中，这可以归结为告诉编译器和硬件它们不能做某些事情。对于编译器而言，这很大程度的解决了指令的重排序。对于硬件而言，这很大程度解决了如何编写传递至其他线程的问题。Rust 暴露的排序方式有：

- 顺序一致性（SeqCst）

- 释放 （Release）

- 获取 （Acquire）

- Relaxed

（注意：我们没有暴露 C++ 的 consume 排序）

## 顺序一致性

顺序一致性是所有排序中最强大的。直观上，一个顺序一致性操作是不可被重新排列的：所有在一个线程的访问不论在 SeqCst 的前后都是不会变的。只使用原子操作以及数据访问的程序是没有数据竞争的，因为有一个单独的全局的程序执行使得所有的线程都达成一致。这种执行也有很好的原因：每个线程仅仅执行流程的交叉部分。如果使用更弱的原子排序，这一定并不一定能有效。

对开发者友好的顺序一致性相对来说并不是免费的。即使在强顺序平台的顺序一致性也存在内存屏障（memory fences）。

实际上，顺序一致性很少是程序正确性的必要条件。然而在不确定其他的选择下，顺序一致性绝对是最正确的选择。程序运行的慢一点肯定是要比它运行错误来的对！将它变为具有更弱一致性的原子操作也很容易，只要把 SeqCst 变成 Relaxed 就好了！当然，证明这种变化的正确性就是另外一个问题了。

## 获取 - 释放

获取和释放是成对出现的。它们的名字就暗示了用法：它们非常适合获取和释放锁，同时确保临界区不会重叠。

直观来看一个获取访问能确保每个访问在它之后；出现在其前的操作可能会被排至其后。同样的一个释放访问确保了每个访问在其前；在其后的操作可能会被排至其前。

当线程 A 释放了一块内存，线程 B 接着获取同样的内存地址，因果关系便建立了。每个写（包括 non-atomic 和 relaxed-atomic 的写）在线程 A 释放之前，可以被 B 获取后观察到，但是这没有与任何其他线程建立因果关系。同样的，如果 A 和 B 访问的是不同位置的内存，那么它们也没有建立因果关系。

获取 - 释放的基本用法便很简单：获取了一块内存地址进入临界区，接着释放该地址。例如一个简单的自旋锁如下：

```rs
use std::sync::Arc;
use std::sync::atomic::{AtomicBool, Ordering};
use std::thread;

fn main() {
    let lock = Arc::new(AtomicBool::new(false)); // value answers "am I locked?"

    // ... distribute lock to threads somehow ...

    // Try to acquire the lock by setting it to true
    while lock.compare_and_swap(false, true, Ordering::Acquire) { }
    // broke out of the loop, so we successfully acquired the lock!

    // ... scary data accesses ...

    // ok we're done, release the lock
    lock.store(false, Ordering::Release);
}
```

在强顺序平台上，大多数的访问都有释放和获取的语义，释放和获取通常是无开销的。不过在弱顺序平台上不是这样。

## Relaxed

Relaxed 访问是最弱的。它们可以被随意重排，也没有先后关系。但是 Relaxed 操作依然是原子的。也就是说，它并不算是数据访问，所有对它的读 - 修改 - 写操作都是原子的。Relaxed 操作适用于那些你希望发生但又并不特别在意的事情。比如，多线程可以使用 Relaxed 的 fetch_add 来增加计数器，如果你不使用计数器的值去同步其他的访问，这个操作就是安全的。

在强顺序平台上使用 Relaxed 没什么好处，因为它们通常都有释放 - 获取语义。不过，在弱顺序平台上，Relaxed 可以获取更小的开销。
